{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57207364-0bf6-4a1b-8aa6-3a4b8fc2807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059441e40d7b4ab681f4fe11ef499e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from FCN3 import *\n",
    "# In your IPython Notebook (Revised)\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import Tuple\n",
    "import standard_hyperparams as hp\n",
    "from logger import *\n",
    "def activation(x):\n",
    "    return x\n",
    "# --- Hyperparameters ---\n",
    "input_dimension: int = 10\n",
    "T = 1.0\n",
    "kappa = T\n",
    "\n",
    "hidden_width1: int = 100\n",
    "hidden_width2: int = 100\n",
    "\n",
    "λ1 = T * input_dimension #weight decay factor\n",
    "λ2 = T * hidden_width1\n",
    "λ3 = T * hidden_width2\n",
    "\n",
    "weight_sigma1: float = 1.0/input_dimension\n",
    "weight_sigma2: float = 1.0/hidden_width1\n",
    "weight_sigma3: float = 1.0/(hidden_width2)\n",
    "num_data_points: int = 500\n",
    "batch_size: int = 100\n",
    "learning_rate: float = 0.001\n",
    "noise_std_ld: float = (2 * learning_rate * T )**0.5\n",
    "num_epochs: int = 500\n",
    "\n",
    "weight_decay_config: dict = {\n",
    "            'fc1.weight': λ1,\n",
    "            'fc2.weight': λ2,\n",
    "            'fc3.weight': λ3,\n",
    "            'fc1.bias': 0.0,\n",
    "            'fc2.bias': 0.0,\n",
    "            'fc3.bias': 0.0,\n",
    "}\n",
    "\n",
    "teacher : SimpleNet = SimpleNet(\n",
    "    input_dimension,\n",
    "    linear_activation,\n",
    "    1/input_dimension\n",
    ").to(hp.DEVICE)\n",
    "# Generate a Dataset out of a teacher network\n",
    "raw_X = HypersphereData.sample_hypersphere(num_data_points, input_dimension, normalized=True).to(hp.DEVICE)\n",
    "raw_Y = (teacher(raw_X).detach())\n",
    "hypersphere_dataset: DataManager = DataManager(raw_X, raw_Y, split = 0.8)\n",
    "\n",
    "train_data_subset: TensorDataset = hypersphere_dataset.train_dataset\n",
    "train_X : torch.Tensor = hypersphere_dataset.tensors[0][train_data_subset.indices]\n",
    "train_Y : torch.Tensor = hypersphere_dataset.tensors[1][train_data_subset.indices]\n",
    "test_data_subset: TensorDataset = hypersphere_dataset.test_dataset\n",
    "test_X : torch.Tensor = hypersphere_dataset.tensors[0][test_data_subset.indices]\n",
    "test_Y : torch.Tensor = hypersphere_dataset.tensors[1][test_data_subset.indices]\n",
    "\n",
    "weight_sigma = (weight_sigma1,\n",
    "    weight_sigma2,\n",
    "    weight_sigma3)\n",
    "\n",
    "# --- Initialize Network ---\n",
    "# Example: Linear activation network\n",
    "hyperparameters : Dict = {\n",
    "    'input_dimension': input_dimension,\n",
    "    'hidden_width_1': hidden_width1,\n",
    "    'hidden_width_2': hidden_width2,\n",
    "    'activation': activation,\n",
    "    'output_activation': activation,\n",
    "    'weight_sigma1': weight_sigma1,\n",
    "    'weight_sigma2': weight_sigma2,\n",
    "    'weight_sigma3': weight_sigma3,\n",
    "}\n",
    "langevin_model: FCN3Network = FCN3Network.model_from_hyperparameters(hyperparameters).to(hp.DEVICE)\n",
    "\n",
    "standard_model: FCN3Network = FCN3Network.model_from_hyperparameters(hyperparameters).to(hp.DEVICE)\n",
    "\n",
    "trainer : NetworkTrainer = NetworkTrainer(\n",
    "    model=standard_model,\n",
    "    manager=hypersphere_dataset,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay_config=weight_decay_config,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "\n",
    "langevin_trainer : LangevinTrainer = LangevinTrainer(\n",
    "    model=langevin_model,\n",
    "    manager=hypersphere_dataset,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    noise_std=noise_std_ld,\n",
    "    weight_decay_config=weight_decay_config,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "def epoch_save_generic(model,trainer):\n",
    "  if trainer.current_epoch % 50 == 0:\n",
    "\n",
    "    # Save the Langevin model\n",
    "    filename = f\"./fcn3_generic.pth\"\n",
    "    # torch.save(trainer.model.state_dict(), filename)\n",
    "    print(f\"Langevin model saved to: {filename}\")\n",
    "\n",
    "def lang_save(trainer):\n",
    "  #epoch_save_generic(trainer, \"langevin_model\")\n",
    "  return\n",
    "\n",
    "def std_save(trainer):\n",
    "  # epoch_save_generic(trainer, \"standard_model\")\n",
    "  return\n",
    "\n",
    "# print(\"Beginning Langevin training\")\n",
    "# loggerlang = Logger(num_epochs=num_epochs,\n",
    "#                 description=f\"Training YURI 1\")\n",
    "\n",
    "with loggerlang:\n",
    "    langevin_trainer.train(logger=loggerlang);\n",
    "\n",
    "\n",
    "loggerreg = Logger(num_epochs=num_epochs,\n",
    "                description=f\"Training YURI 1\")\n",
    "\n",
    "with loggerreg:\n",
    "    trainer.train(logger=loggerreg);    \n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "gd_loss = trainer.training_info.trainloss\n",
    "langevin_loss = langevin_trainer.training_info.trainloss\n",
    "# Plot train and test loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(langevin_loss)), langevin_loss, label='Langevin Dynamics Loss')\n",
    "plt.plot(range(len(gd_loss)), gd_loss, label='Vanilla GD Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Linear FCN3 Network Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add a grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8f4a5-b820-4e20-8077-6ee70a1e4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "langevin_trai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0168f47-5756-430a-8d1a-9a600cec842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# gd_loss = trainer.training_info.trainloss\n",
    "langevin_loss = langevin_trainer.training_info.trainloss\n",
    "# Plot train and test loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(langevin_loss)), langevin_loss, label='Langevin Dynamics Loss')\n",
    "# plt.plot(range(len(gd_loss)), gd_loss, label='Vanilla GD Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Linear FCN3 Network Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add a grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349ff1c-e4b3-4958-93a4-84deb6f7cb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
